{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "'\\t\\n\\x0b\\x0c\\r '\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print string.ascii_letters\n",
    "print repr(string.whitespace)\n",
    "print string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A wild m—dash!\n",
      "This is an ascii string. It is the default in Python.\n",
      "A wild m&#8212;dash!\n"
     ]
    }
   ],
   "source": [
    "# Note the 'u' at the beginnning of the unicode string!\n",
    "# Unicode can poison your script when you write to a file,\n",
    "# especially if it is mixed with ascii. Beware of\n",
    "# utf-16 and utf-32 encoded text...\n",
    "\n",
    "unicodeStr = u'A wild m—dash!'\n",
    "asciiStr = 'This is an ascii string. It is the default in Python.'\n",
    "\n",
    "print unicodeStr\n",
    "print asciiStr\n",
    "\n",
    "unicodeStr = unicodeStr.encode('ascii', 'xmlcharrefreplace') # or 'ignore'\n",
    "\n",
    "with open(\"foo.txt\", \"w\") as outfile:\n",
    "    outfile.write(unicodeStr)\n",
    "    \n",
    "print unicodeStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sarah', 'went', 'to', 'the', 'store', 'to', 'buy', 'some', 'milk', 'or', 'something.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization is the process of processing \n",
    "# natural langauge strings into lists of words...\n",
    "\n",
    "sentence = \"Sarah went to the store to buy some milk or something.\"\n",
    "tokens = sentence.split()\n",
    "print tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sarah', 'went', 'to', 'the', 'store', 'to', 'buy', 'some', 'milk', 'or', 'something']\n",
      "['Sarah', ' ', 'went', ' ', 'to', ' ', 'the', ' ', 'store', ' ', 'to', ' ', 'buy', ' ', 'some', ' ', 'milk', ' ', 'or', ' ', 'something', '.']\n"
     ]
    }
   ],
   "source": [
    "# Time for some basic regex...\n",
    "import re\n",
    "\n",
    "print re.findall(r\"\\w+\", sentence)\n",
    "print re.findall(r\"\\w+|\\W+\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sarah', 's', 'gone', 'to', 'buy', 'some', 'milk', 'or', 'something', 'Don', 't', 'forget', 'the_bread', 'yelled', 'Susan']\n",
      "['Sarah', \"'\", 's', ' ', 'gone', ' ', 'to', ' ', 'buy', ' ', 'some', \" '\", 'milk', \"' \", 'or', ' ', 'something', \". '\", 'Don', \"'\", 't', ' ', 'forget', ' ', 'the_bread', \",' \", 'yelled', ' ', 'Susan', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Sarah\\'s gone to buy some \\'milk\\' or something. \\'Don't forget the_bread,\\' yelled Susan.\"\n",
    "\n",
    "print re.findall(r\"\\w+\", sentence)\n",
    "print re.findall(r\"\\w+|\\W+\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Sarah's\", 'gone', 'to', 'buy', 'some', 'milk', 'or', 'something', \"Don't\", 'forget', 'the_bread', 'yelled', 'Susan']\n",
      "[\"Sarah's\", None, ' ', 'gone', None, ' ', 'to', None, ' ', 'buy', None, ' ', 'some', \" '\", None, 'milk', \"' \", None, 'or', None, ' ', 'something', \". '\", None, \"Don't\", None, ' ', 'forget', None, ' ', 'the', None, '_', 'bread', \",' \", None, 'yelled', None, ' ', 'Susan', None, '.', '']\n"
     ]
    }
   ],
   "source": [
    "print re.findall(r\"\\b[\\w+']+\\b\", sentence)\n",
    "\n",
    "# Now done with splitting, and lowercase... but note the empty string as the final token!\n",
    "tokens = re.split(r\"[^a-zA-Z0-9]{2,}|[^a-zA-Z0-9']+\", sentence)\n",
    "\n",
    "print tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SARAH'S\", 'GONE', 'TO', 'BUY', 'SOME', 'MILK', 'OR', 'SOMETHING', \"DON'T\", 'FORGET', 'THE', 'BREAD', 'YELLED', 'SUSAN']\n"
     ]
    }
   ],
   "source": [
    "# List comprehensions!\n",
    "\n",
    "capsLockTokens = [t.upper() for t in tokens if t]\n",
    "\n",
    "print capsLockTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: \"Sarah's\", 1: 'gone', 2: 'to', 3: 'buy', 4: 'some', 5: 'milk', 6: 'or', 7: 'something', 8: \"Don't\", 9: 'forget', 10: 'the', 11: 'bread', 12: 'yelled', 13: 'Susan'}\n",
      "{0: \"Sarah's\", 1: 'gone', 2: 'to', 3: 'buy', 4: 'some', 5: 'milk', 6: 'or', 7: 'something', 8: \"Don't\", 9: 'forget', 10: 'the', 11: 'bread', 12: 'yelled', 13: 'Susan', 14: ''}\n",
      "[\"SARAH'S\", 'GONE', 'TO', 'BUY', 'SOME', 'MILK', 'OR', 'SOMETHING', \"DON'T\", 'FORGET', 'THE', 'BREAD', 'YELLED', 'SUSAN', 'FOO!']\n"
     ]
    }
   ],
   "source": [
    "# Dict comprehensions!\n",
    "\n",
    "tokenDict = {i:tokens[i] for i in range(len(tokens)) if tokens[i]}\n",
    "\n",
    "print tokenDict\n",
    "\n",
    "# But usually, this is better...\n",
    "print dict(enumerate(tokens))\n",
    "\n",
    "# If / else statements in list or dict comprehensions can\n",
    "# also look like this...\n",
    "\n",
    "print [t.upper() if t else \"FOO!\" for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', \"Don't\", \"Sarah's\", 'Susan', 'bread', 'buy', 'forget', 'gone', 'milk', 'or', 'some', 'something', 'the', 'to', 'yelled']\n",
      "['', 'bread', 'buy', \"don't\", 'forget', 'gone', 'milk', 'or', \"sarah's\", 'some', 'something', 'susan', 'the', 'to', 'yelled']\n",
      "['', 'or', 'to', 'buy', 'the', 'gone', 'milk', 'some', 'bread', \"don't\", 'susan', 'forget', 'yelled', \"sarah's\", 'something']\n",
      "something\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sorting... finally a use for the lambda function\n",
    "\n",
    "tokens.sort()\n",
    "\n",
    "print tokens\n",
    "\n",
    "tokens = map(lambda x: x.lower(), tokens)\n",
    "\n",
    "tokens.sort()\n",
    "\n",
    "print tokens\n",
    "\n",
    "print sorted(tokens, key=lambda x: len(x))\n",
    "\n",
    "print max(tokens, key=lambda x: len(x))\n",
    "\n",
    "print min(tokens, key=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
